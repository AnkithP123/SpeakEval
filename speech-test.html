<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Speech API Test - SpeakEval</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        .container {
            background: white;
            padding: 30px;
            border-radius: 12px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        
        .control-section {
            margin-bottom: 30px;
            padding: 20px;
            background-color: #f8f9fa;
            border-radius: 8px;
            border: 1px solid #e9ecef;
        }
        
        .control-section h3 {
            margin-top: 0;
            color: #495057;
        }
        
        .language-selector {
            margin-bottom: 20px;
        }
        
        .language-selector select {
            padding: 8px 12px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
            width: 200px;
        }
        
        .button-group {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
        }
        
        button {
            padding: 12px 24px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 16px;
            font-weight: 500;
            transition: background-color 0.3s ease;
        }
        
        .start-btn {
            background-color: #28a745;
            color: white;
        }
        
        .start-btn:hover {
            background-color: #218838;
        }
        
        .stop-btn {
            background-color: #dc3545;
            color: white;
        }
        
        .stop-btn:hover {
            background-color: #c82333;
        }
        
        .stop-btn:disabled {
            background-color: #6c757d;
            cursor: not-allowed;
        }
        
        .status {
            padding: 10px;
            border-radius: 4px;
            margin-bottom: 20px;
            font-weight: 500;
        }
        
        .status.listening {
            background-color: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        
        .status.stopped {
            background-color: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        
        .status.not-supported {
            background-color: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }
        
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        
        .status.listening .status-indicator {
            background-color: #28a745;
            animation: pulse 1.5s infinite;
        }
        
        .status.stopped .status-indicator {
            background-color: #dc3545;
        }
        
        .status.not-supported .status-indicator {
            background-color: #ffc107;
        }
        
        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
                opacity: 1;
            }
            50% {
                transform: scale(1.1);
                opacity: 0.7;
            }
        }
        
        .results {
            margin-top: 20px;
        }
        
        .result-box {
            background-color: #e7f3ff;
            border: 1px solid #0ea5e9;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 10px;
            word-wrap: break-word;
        }
        
        .result-box h4 {
            margin: 0 0 10px 0;
            color: #0f172a;
            font-size: 16px;
        }
        
        .result-text {
            font-style: italic;
            color: #374151;
            line-height: 1.5;
            margin-bottom: 10px;
        }
        
        .result-meta {
            font-size: 12px;
            color: #6b7280;
            margin-top: 10px;
        }
        
        .console-log {
            background-color: #1e293b;
            color: #e2e8f0;
            padding: 15px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            white-space: pre-wrap;
            max-height: 200px;
            overflow-y: auto;
            margin-top: 10px;
        }
        
        .clear-btn {
            background-color: #6c757d;
            color: white;
            padding: 8px 16px;
            font-size: 14px;
        }
        
        .clear-btn:hover {
            background-color: #5a6268;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Web Speech API Test - SpeakEval</h1>
        
        <div class="control-section">
            <h3>Speech Recognition Controls</h3>
            
            <div class="language-selector">
                <label for="language">Recognition Language:</label>
                <select id="language">
                    <option value="en-US">English (US)</option>
                    <option value="en-GB">English (UK)</option>
                    <option value="es-ES">Spanish (Spain)</option>
                    <option value="es-US">Spanish (US)</option>
                    <option value="fr-FR">French</option>
                    <option value="de-DE">German</option>
                    <option value="it-IT">Italian</option>
                    <option value="pt-BR">Portuguese (Brazil)</option>
                    <option value="zh-CN">Chinese (Mandarin)</option>
                    <option value="ja-JP">Japanese</option>
                    <option value="ko-KR">Korean</option>
                    <option value="ru-RU">Russian</option>
                    <option value="hi-IN">Hindi</option>
                </select>
            </div>
            
            <div class="button-group">
                <button id="startBtn" class="start-btn">üé§ Start Recording</button>
                <button id="stopBtn" class="stop-btn" disabled>‚èπÔ∏è Stop Recording</button>
                <button id="clearBtn" class="clear-btn">üóëÔ∏è Clear Results</button>
            </div>
            
            <div id="status" class="status stopped">
                <span class="status-indicator"></span>
                <span id="statusText">Speech recognition stopped</span>
            </div>
        </div>
        
        <div class="results">
            <h3>Recognition Results</h3>
            <div id="liveResults" class="result-box" style="display: none;">
                <h4>üî¥ Live Recognition (Interim Results)</h4>
                <div id="interimText" class="result-text">Listening for speech...</div>
            </div>
            
            <div id="finalResults" class="result-box" style="display: none;">
                <h4>‚úÖ Final Recognition Results</h4>
                <div id="finalText" class="result-text"></div>
                <div id="finalMeta" class="result-meta"></div>
            </div>
            
            <h4>Console Output</h4>
            <div id="consoleLog" class="console-log">Ready to start speech recognition...\n</div>
        </div>
    </div>

    <script>
        // Web Speech API implementation similar to AudioRecorder.jsx
        let recognition = null;
        let isListening = false;
        let recognizedText = "";
        let finalRecognizedTextRef = ""; // Simulate the ref from AudioRecorder
        let selectedLanguage = "en-US";
        
        // Elements
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const clearBtn = document.getElementById('clearBtn');
        const statusDiv = document.getElementById('status');
        const statusText = document.getElementById('statusText');
        const languageSelect = document.getElementById('language');
        const liveResultsDiv = document.getElementById('liveResults');
        const finalResultsDiv = document.getElementById('finalResults');
        const interimText = document.getElementById('interimText');
        const finalText = document.getElementById('finalText');
        const finalMeta = document.getElementById('finalMeta');
        const consoleLog = document.getElementById('consoleLog');
        
        // Console logging function
        function addToConsole(message) {
            const timestamp = new Date().toLocaleTimeString();
            consoleLog.textContent += `[${timestamp}] ${message}\n`;
            consoleLog.scrollTop = consoleLog.scrollHeight;
            console.log(message); // Also log to browser console
        }
        
        // Check if Web Speech API is supported
        function checkSpeechSupport() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            
            if (!SpeechRecognition) {
                statusDiv.className = 'status not-supported';
                statusText.textContent = 'Web Speech API not supported in this browser';
                startBtn.disabled = true;
                addToConsole('‚ùå Web Speech API not supported');
                return false;
            }
            
            addToConsole('‚úÖ Web Speech API is supported');
            return true;
        }
        
        // Initialize speech recognition (matches new AudioRecorder implementation)
        function initializeSpeechRecognition() {
            if (!checkSpeechSupport()) return null;
            
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            const newRecognition = new SpeechRecognition();
            
            // Configure recognition settings (same as AudioRecorder.jsx)
            newRecognition.continuous = true;
            newRecognition.interimResults = true;
            newRecognition.lang = selectedLanguage;
            
            addToConsole(`üåê Speech recognition initialized with language: ${selectedLanguage}`);
            
            // Handle recognition results (matches new implementation)
            newRecognition.onresult = (event) => {
                let finalTranscript = "";
                let interimTranscript = "";
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Update recognized text with final results (same as AudioRecorder.jsx)
                if (finalTranscript) {
                    recognizedText += finalTranscript;
                    finalRecognizedTextRef = recognizedText; // Update ref immediately
                    
                    finalText.textContent = `"${recognizedText}"`;
                    finalMeta.textContent = `Language: ${selectedLanguage} | Total length: ${recognizedText.length} characters`;
                    finalResultsDiv.style.display = 'block';
                    
                    // Console log (same as AudioRecorder.jsx)
                    addToConsole(`üé§ Speech recognized (final): "${finalTranscript}"`);
                    addToConsole(`üé§ Total recognized text so far: "${recognizedText}"`);
                }
                
                // Store interim results separately so we can capture them when stopping
                if (interimTranscript) {
                    // Store interim text so it persists and can be accessed when stopping
                    newRecognition.lastInterimText = interimTranscript;
                    interimText.textContent = `"${interimTranscript}"`;
                    liveResultsDiv.style.display = 'block';
                    addToConsole(`üé§ Interim speech: "${interimTranscript}"`);
                }
            };
            
            // Handle errors (same as AudioRecorder.jsx)
            newRecognition.onerror = (event) => {
                addToConsole(`‚ùå Speech recognition error: ${event.error}`);
                if (event.error === 'not-allowed') {
                    addToConsole('‚ùå Microphone access denied for speech recognition');
                    statusDiv.className = 'status not-supported';
                    statusText.textContent = 'Microphone access denied';
                }
            };
            
            // Handle end of recognition (matches new implementation)
            newRecognition.onend = () => {
                addToConsole('üé§ Speech recognition ended');
                
                // Capture any remaining interim text as final text when recognition ends
                if (newRecognition.lastInterimText) {
                    recognizedText += newRecognition.lastInterimText;
                    finalRecognizedTextRef = recognizedText; // Update ref immediately
                    
                    finalText.textContent = `"${recognizedText}"`;
                    finalMeta.textContent = `Language: ${selectedLanguage} | Total length: ${recognizedText.length} characters`;
                    finalResultsDiv.style.display = 'block';
                    
                    addToConsole(`üé§ Capturing final interim text on end: "${newRecognition.lastInterimText}"`);
                    addToConsole(`üé§ Final total recognized text: "${recognizedText}"`);
                    
                    newRecognition.lastInterimText = ""; // Clear interim text
                }
                
                isListening = false;
                updateUI();
            };
            
            // Handle start of recognition (same as AudioRecorder.jsx)
            newRecognition.onstart = () => {
                addToConsole('üé§ Speech recognition started');
                newRecognition.lastInterimText = ""; // Clear any previous interim text
                isListening = true;
                updateUI();
            };
            
            return newRecognition;
        }
        
        // Update UI based on current state
        function updateUI() {
            if (isListening) {
                statusDiv.className = 'status listening';
                statusText.textContent = `Listening for speech in ${selectedLanguage}...`;
                startBtn.disabled = true;
                stopBtn.disabled = false;
                liveResultsDiv.style.display = 'block';
                interimText.textContent = 'Listening for speech...';
            } else {
                statusDiv.className = 'status stopped';
                statusText.textContent = 'Speech recognition stopped';
                startBtn.disabled = false;
                stopBtn.disabled = true;
                liveResultsDiv.style.display = 'none';
            }
        }
        
        // Start speech recognition
        function startSpeechRecognition() {
            if (!recognition) {
                recognition = initializeSpeechRecognition();
                if (!recognition) return;
            }
            
            try {
                recognition.lang = selectedLanguage; // Update language
                recognition.start();
                addToConsole(`üé§ Starting speech recognition with language: ${selectedLanguage}`);
            } catch (error) {
                addToConsole(`‚ùå Error starting speech recognition: ${error.message}`);
            }
        }
        
        // Stop speech recognition (matches new implementation)
        function stopSpeechRecognition() {
            if (recognition && isListening) {
                // Capture any remaining interim text before stopping (same as new AudioRecorder.jsx)
                if (recognition.lastInterimText) {
                    recognizedText += recognition.lastInterimText;
                    finalRecognizedTextRef = recognizedText; // Update ref immediately
                    
                    finalText.textContent = `"${recognizedText}"`;
                    finalMeta.textContent = `Language: ${selectedLanguage} | Total length: ${recognizedText.length} characters`;
                    finalResultsDiv.style.display = 'block';
                    
                    addToConsole(`üé§ Capturing final interim text before stop: "${recognition.lastInterimText}"`);
                    addToConsole(`üé§ Final total recognized text before stop: "${recognizedText}"`);
                    recognition.lastInterimText = ""; // Clear interim text
                }
                
                recognition.stop();
                addToConsole('üé§ Speech recognition stopped manually');
                addToConsole(`üé§ Final text in ref after stop: "${finalRecognizedTextRef}"`);
                
                // Simulate the console output from AudioRecorder.jsx (using ref)
                setTimeout(() => {
                    const finalTextFromRef = finalRecognizedTextRef || recognizedText;
                    
                    if (finalTextFromRef) {
                        addToConsole(`üé§ Final recognized speech text after stopping: "${finalTextFromRef}"`);
                        addToConsole(`üé§ Text length: ${finalTextFromRef.length}`);
                        
                        // Simulate what would be sent to backend (same as AudioRecorder.jsx)
                        const uploadData = {
                            uploaded: true,
                            speechRecognitionText: finalTextFromRef || null,
                            recognitionLanguage: selectedLanguage
                        };
                        addToConsole('üì§ Data that would be sent to backend:');
                        addToConsole(JSON.stringify(uploadData, null, 2));
                        addToConsole('üì§ Speech text from ref: "' + finalRecognizedTextRef + '"');
                        addToConsole('üì§ Speech text from state: "' + recognizedText + '"');
                        
                        // Simulate server response logging (same as AudioRecorder.jsx)
                        setTimeout(() => {
                            addToConsole('üé§ Web Speech API Recognition Results:');
                            addToConsole(JSON.stringify({
                                recognizedText: finalTextFromRef || "(no text recognized)",
                                language: selectedLanguage,
                                textLength: finalTextFromRef ? finalTextFromRef.length : 0
                            }, null, 2));
                            
                            // Simulate server transcription comparison
                            addToConsole('üéµ Server Transcription Results:');
                            addToConsole(JSON.stringify({
                                transcription: "[would come from server AI transcription]",
                                textLength: "[server transcription length]"
                            }, null, 2));
                        }, 1000);
                    } else {
                        addToConsole('üé§ No speech was recognized');
                        addToConsole('üé§ Final recognized speech text after stopping: "(no text detected)"');
                    }
                }, 100); // Same delay as AudioRecorder.jsx
            }
        }
        
        // Clear all results
        function clearResults() {
            recognizedText = "";
            finalRecognizedTextRef = ""; // Clear ref as well
            finalText.textContent = "";
            finalMeta.textContent = "";
            interimText.textContent = "Listening for speech...";
            finalResultsDiv.style.display = 'none';
            liveResultsDiv.style.display = 'none';
            consoleLog.textContent = "Ready to start speech recognition...\n";
            addToConsole('üóëÔ∏è Results cleared');
        }
        
        // Event listeners
        startBtn.addEventListener('click', () => {
            // Reset recognized text for new recording (same as AudioRecorder.jsx)
            recognizedText = "";
            finalRecognizedTextRef = ""; // Reset ref as well
            addToConsole('üé§ Reset recognized text for new recording');
            
            startSpeechRecognition();
        });
        stopBtn.addEventListener('click', stopSpeechRecognition);
        clearBtn.addEventListener('click', clearResults);
        
        languageSelect.addEventListener('change', (e) => {
            selectedLanguage = e.target.value;
            addToConsole(`üåê Language changed to: ${selectedLanguage}`);
            
            // Update recognition language if currently listening
            if (recognition && isListening) {
                recognition.stop();
                setTimeout(() => {
                    startSpeechRecognition();
                }, 500);
            }
        });
        
        // Initialize on page load
        checkSpeechSupport();
        updateUI();
        addToConsole('üé§ Web Speech API Test initialized');
        addToConsole('üé§ This demonstrates the same functionality implemented in AudioRecorder.jsx');
        addToConsole('üé§ Updated to match the new ref-based implementation');
    </script>
</body>
</html>